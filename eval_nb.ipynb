{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1934c36-7f67-4077-ac3b-091b27afa6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from oxford_pets_train_script import *\n",
    "import torchvision.transforms.functional as F\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.io import read_image\n",
    "from pathlib import Path\n",
    "from torchvision.utils import draw_bounding_boxes, draw_segmentation_masks\n",
    "from torchvision.transforms.functional import convert_image_dtype\n",
    "\n",
    "# https://pytorch.org/vision/0.10/auto_examples/plot_visualization_utils.html\n",
    "# boxes and masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b3927a-512f-48a0-bfdd-65a92997075b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(imgs):\n",
    "    if not isinstance(imgs, list):\n",
    "        imgs = [imgs]\n",
    "    fix, axs = plt.subplots(ncols=len(imgs), squeeze=False)\n",
    "    for i, img in enumerate(imgs):\n",
    "        img = img.detach()\n",
    "        img = F.to_pil_image(img)\n",
    "        axs[0, i].imshow(np.asarray(img))\n",
    "        axs[0, i].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
    "\n",
    "mean=-np.array([0.485, 0.456, 0.406])\n",
    "std= 1/np.array([0.229, 0.224, 0.225])\n",
    "inverse_norm= transforms.Compose([transforms.Normalize(mean=[0.0,0.0,0.0], std=std), transforms.Normalize(mean=mean, std=[1,1,1])])\n",
    "\n",
    "def draw_bb(normed_img_data, boxes):\n",
    "    reg_img = inverse_norm(normed_img_data)\n",
    "    reg_img = convert_image_dtype(reg_image,dtype=torch.uint8).to(\"cpu\")\n",
    "    boxed_img = draw_bounding_boxes(reg_image, boxes)\n",
    "    return boxed_img\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2645fc22-96a2-4c7c-a16b-c41254ba1c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs, ds, ts = gen_dataset()\n",
    "\n",
    "fs, ds, ts = gen_dataset()\n",
    "\n",
    "model = torch.load(\"checkpoint_13\").to(device)\n",
    "tdata, tlabel = ts[100]\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    preds = model([tdata])\n",
    "\n",
    "reg_image = convert_image_dtype(inverse_norm(tdata.clone()),dtype=torch.uint8).to(\"cpu\")\n",
    "reg_image_w_boxes = draw_bounding_boxes(reg_image, preds[0][\"boxes\"][:3])\n",
    "reg_image_w_mask = draw_segmentation_masks(reg_image, masks=preds[0][\"masks\"][0]>0.5, alpha=0.7)\n",
    "reg_image_w_box_w_mask = draw_bounding_boxes(draw_segmentation_masks(reg_image, masks=preds[0][\"masks\"][0]>0.5, alpha=0.7), preds[0][\"boxes\"][:1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522a5e47-3175-4e98-a845-458f7502f391",
   "metadata": {},
   "outputs": [],
   "source": [
    "show([reg_image_w_mask, draw_bb(tdata, preds[0][\"boxes\"][:3])])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
